{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #libreria de python para manipular datos\n",
    "import numpy as np # libreria de python para calculos numericos y analisis\n",
    "import os #modulo para usar funcionalidades del sistema operativo\n",
    "from pathlib import Path # modulo de la ruta que se usa\n",
    "from heapq import merge # modulo para unir Dataframes\n",
    "import re\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns',None)#Cuantas columnas mostar por Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separador = os.path.sep #busca el separador que sería / o \\\n",
    "current_dir = os.path.dirname(os.path.realpath('CruceUsuariosAPPrezagos.ipynb'))  #busca la ruta del archivo en el que está CruceUsuariosAPP.ipynb\n",
    "dir = separador.join(current_dir.split(separador)[:-1]) #se devuelve una carpeta\n",
    "filenameT = os.path.join(dir, \"Data\\\\SO\")\n",
    "filename = os.path.join(dir, \"Resultado\\\\Primario\") \n",
    "filenameS= os.path.join(dir,\"Data\\\\USUARIOS\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exists_Usuarios = os.path.exists(filename+\"\\\\IdentidadesEncontradasconSSFF.csv\")\n",
    "print(file_exists_Usuarios) #muestra false o true \n",
    "\n",
    "if file_exists_Usuarios == True: #Si el archivo existe\n",
    "\n",
    "    Usuarios=pd.read_csv(filename+\"\\\\IdentidadesEncontradasconSSFF.csv\", sep=';', encoding = \"utf-8-sig\" , engine='python') #importa el archivo csv separado por punto y comas\n",
    "   \n",
    "    Usuarios= Usuarios[['DocumentoRRHH', 'Identidad','NombreRRHH', 'CASO', 'FECHA DE RETIRO','TIPO DE CONTRATO' ,'Usuario_Aplicativo', 'Aplica Inactivacion']]\n",
    "    UsuariosD = Usuarios[['DocumentoRRHH']]\n",
    "    UsuariosD.drop(UsuariosD[(UsuariosD['DocumentoRRHH'] =='0') | (UsuariosD['DocumentoRRHH'] == 0)].index, inplace=True)\n",
    "    Usuarios['DocumentoRRHH'] = Usuarios['DocumentoRRHH'].astype(str)\n",
    "    Usuarios = Usuarios[Usuarios['Aplica Inactivacion']==\"si\"]\n",
    "    Usuarios = Usuarios.drop('Aplica Inactivacion',  axis=1)\n",
    "    Usuarios = Usuarios.drop('Usuario_Aplicativo',  axis=1)\n",
    "    UsuariosD['DocumentoRRHH'] = UsuariosD['DocumentoRRHH'].astype(str)\n",
    "    Usuarios[\"Identidad\"]= Usuarios[\"Identidad\"].str.lower()\n",
    "    UsuariosD=UsuariosD.drop_duplicates() #Quita filas que tengan el mismo documento\n",
    "    Identidades=Usuarios[['Identidad']]\n",
    "    Identidades=Identidades.drop_duplicates()\n",
    "    Identidades=Identidades['Identidad'].tolist()\n",
    "    Documento=UsuariosD[['DocumentoRRHH']]\n",
    "    # doc = Documento[\"DocumentoRRHH\"].str.split(\".\", n=1, expand=True)\n",
    "    # doc= pd.DataFrame(doc)\n",
    "    # doc.columns = ['doc', 'punto']\n",
    "    # Documento = pd.concat([Documento, doc], axis=1)\n",
    "    # Documento=Documento[['doc']] #USAR SOLO ESAS TRES COLUMNAS\n",
    "    # Documento.rename(columns={'doc':'DocumentoRRHH'}, inplace=True)\n",
    "    Documento=Documento.drop_duplicates()\n",
    "    Documento=Documento['DocumentoRRHH'].tolist()\n",
    "    Usuarios1= Usuarios[['DocumentoRRHH', 'NombreRRHH', 'CASO', 'FECHA DE RETIRO','TIPO DE CONTRATO']]\n",
    "    Usuarios2= Usuarios[['DocumentoRRHH', 'Identidad','NombreRRHH', 'CASO', 'FECHA DE RETIRO','TIPO DE CONTRATO']]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro1 = pd.DataFrame()\n",
    "file_exists_SO = os.path.exists(filenameT+\"\\\\SO.xlsx\")\n",
    "\n",
    "print(file_exists_SO)\n",
    "\n",
    "if file_exists_SO == True:\n",
    "    so=pd.read_excel(filenameT+\"\\\\SO.xlsx\")\n",
    "    so=so[['Column2', 'Column3', 'Column4', 'Column7',  'Column5']]\n",
    "    so = so.fillna({'Column7': 'Activo'})\n",
    "    so.rename(columns={'Column2': 'Nombre_SO', 'Column3':'Identidad', 'Column4':'Nombre', 'Column7':'Estado', 'Column5':'Documento'}, inplace=True)\n",
    "    so['Identidad'] = so['Identidad'].astype(str)\n",
    "    so['Documento'] = so['Documento'].astype(str)\n",
    "    so[\"Identidad\"] = so[\"Identidad\"].str.lower()\n",
    "    so['Documento'] = so['Documento'].astype(str).str.replace(\".\", \"\", regex=True)\n",
    "    so['Nombre'] = so['Nombre'].astype(str).str.replace(\".\", \"\", regex=True)\n",
    "    so[\"Identidad\"] = [ele.lstrip(' ') for ele in so[\"Identidad\"]]\n",
    "    so[\"Identidad\"] = [ele.rstrip(' ') for ele in so[\"Identidad\"]]\n",
    "    so[\"Identidad\"] = [ele.lstrip('.') for ele in so[\"Identidad\"]]\n",
    "    so[\"Identidad\"] = [ele.rstrip('.') for ele in so[\"Identidad\"]]\n",
    "    so[\"Documento\"] = [ele.lstrip(' ') for ele in so[\"Documento\"]]\n",
    "    so[\"Documento\"] = [ele.rstrip(' ') for ele in so[\"Documento\"]]\n",
    "    so[\"Documento\"] = [ele.lstrip('.') for ele in so[\"Documento\"]]\n",
    "    so[\"Documento\"] = [ele.rstrip('.') for ele in so[\"Documento\"]]\n",
    "    so['Estado'] = so['Estado'].astype(str).str.replace(\"Bloqueado\", \"Inactivo\", regex=True)   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtroId = so[so.Identidad.isin(Identidades)] #filtra de ClaroCo todos los usuarios que existen en la lista (cedulas)\n",
    "filtroId=filtroId.assign(Cruce='Identidad') \n",
    "filtroId = filtroId.merge(Usuarios2, how='left', left_on='Identidad', right_on='Identidad')\n",
    "\n",
    "total = filtroId\n",
    "total= total.drop_duplicates(total.columns[~total.columns.isin(['Cruce'])], keep='first')\n",
    "    \n",
    "total.index = range(total.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exists_SO2 = os.path.exists(filenameT+\"\\\\UserLocales_ServersMovil.csv\")\n",
    "\n",
    "print(file_exists_SO2)\n",
    "\n",
    "if file_exists_SO2 == True:\n",
    "    so2=pd.read_csv(filenameT+\"\\\\UserLocales_ServersMovil.csv\", sep=',', encoding = 'utf-8-sig' , engine='python' )\n",
    "    so2=so2[['Server', 'UserName', 'Active']]\n",
    "    so2.rename(columns={'Server': 'Nombre_SO', 'UserName':'Identidad', 'Active':'Estado'}, inplace=True)\n",
    "    so2[\"Identidad\"] = so2[\"Identidad\"].str.lower()\n",
    "    so2[\"Nombre_SO\"] = so2[\"Nombre_SO\"].str.lower()\n",
    "    so2['Estado'] = so2['Estado'].astype(str).str.replace(\"False\", \"Inactivo\", regex=True)\n",
    "    so2['Estado'] = so2['Estado'].astype(str).str.replace(\"True\", \"Activo\", regex=True)\n",
    "    so2[\"Identidad\"] = [ele.lstrip(' ') for ele in so2[\"Identidad\"]]\n",
    "    so2[\"Identidad\"] = [ele.rstrip(' ') for ele in so2[\"Identidad\"]]\n",
    "    so2[\"Identidad\"] = [ele.lstrip('.') for ele in so2[\"Identidad\"]]\n",
    "    so2[\"Identidad\"] = [ele.rstrip('.') for ele in so2[\"Identidad\"]]\n",
    "    filtroId = so2[so2.Identidad.isin(Identidades)] #filtra de ClaroCo todos los usuarios que existen en la lista (cedulas)\n",
    "    filtroId=filtroId.assign(Cruce='Identidad') \n",
    "    filtroId = filtroId.merge(Usuarios2, how='left', left_on='Identidad', right_on='Identidad')\n",
    "    filtroId= filtroId.drop_duplicates(filtroId.columns[~filtroId.columns.isin(['Cruce'])], keep='first')\n",
    "    total = pd.concat([total, filtroId])\n",
    "    \n",
    "    total.index = range(total.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exists_SO3 = os.path.exists(filenameT+\"\\\\UserLocales_ServersFija.csv\")\n",
    "\n",
    "print(file_exists_SO3)\n",
    "\n",
    "if file_exists_SO3 == True:\n",
    "    so3=pd.read_csv(filenameT+\"\\\\UserLocales_ServersFija.csv\", sep=',', encoding = 'utf-8-sig' , engine='python' )\n",
    "    so3=so3[['Server', 'UserName', 'Active']]\n",
    "    so3.rename(columns={'Server': 'Nombre_SO', 'UserName':'Identidad', 'Active':'Estado'}, inplace=True)\n",
    "    so3[\"Identidad\"] = so3[\"Identidad\"].str.lower()\n",
    "    so3[\"Nombre_SO\"] = so3[\"Nombre_SO\"].str.lower()\n",
    "    so3['Estado'] = so3['Estado'].astype(str).str.replace(\"False\", \"Inactivo\", regex=True)\n",
    "    so3['Estado'] = so3['Estado'].astype(str).str.replace(\"True\", \"Activo\", regex=True)\n",
    "    so3[\"Identidad\"] = [ele.lstrip(' ') for ele in so3[\"Identidad\"]]\n",
    "    so3[\"Identidad\"] = [ele.rstrip(' ') for ele in so3[\"Identidad\"]]\n",
    "    so3[\"Identidad\"] = [ele.lstrip('.') for ele in so3[\"Identidad\"]]\n",
    "    so3[\"Identidad\"] = [ele.rstrip('.') for ele in so3[\"Identidad\"]]\n",
    "    filtroId = so3[so3.Identidad.isin(Identidades)] #filtra de ClaroCo todos los usuarios que existen en la lista (cedulas)\n",
    "    filtroId=filtroId.assign(Cruce='Identidad') \n",
    "    filtroId = filtroId.merge(Usuarios2, how='left', left_on='Identidad', right_on='Identidad')\n",
    "    filtroId= filtroId.drop_duplicates(filtroId.columns[~filtroId.columns.isin(['Cruce'])], keep='first')\n",
    "    total = pd.concat([total, filtroId])\n",
    "    \n",
    "    total.index = range(total.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exists_SO4 = os.path.exists(filenameT+\"\\\\UserLocales_ServersClaroCO.csv\")\n",
    "\n",
    "print(file_exists_SO4)\n",
    "\n",
    "if file_exists_SO4 == True:\n",
    "    so4=pd.read_csv(filenameT+\"\\\\UserLocales_ServersClaroCO.csv\", sep=',', encoding = 'utf-8-sig' , engine='python' )\n",
    "    so4=so4[['Server', 'UserName', 'Active']]\n",
    "    so4.rename(columns={'Server': 'Nombre_SO', 'UserName':'Identidad', 'Active':'Estado'}, inplace=True)\n",
    "    so4[\"Identidad\"] = so4[\"Identidad\"].str.lower()\n",
    "    so4[\"Nombre_SO\"] = so4[\"Nombre_SO\"].str.lower()\n",
    "    so4['Estado'] = so4['Estado'].astype(str).str.replace(\"False\", \"Inactivo\", regex=True)\n",
    "    so4['Estado'] = so4['Estado'].astype(str).str.replace(\"True\", \"Activo\", regex=True)\n",
    "    so4[\"Identidad\"] = [ele.lstrip(' ') for ele in so4[\"Identidad\"]]\n",
    "    so4[\"Identidad\"] = [ele.rstrip(' ') for ele in so4[\"Identidad\"]]\n",
    "    so4[\"Identidad\"] = [ele.lstrip('.') for ele in so4[\"Identidad\"]]\n",
    "    so4[\"Identidad\"] = [ele.rstrip('.') for ele in so4[\"Identidad\"]]\n",
    "\n",
    "    filtroId = so4[so4.Identidad.isin(Identidades)] #filtra de ClaroCo todos los usuarios que existen en la lista (cedulas)\n",
    "    filtroId=filtroId.assign(Cruce='Identidad') \n",
    "    filtroId = filtroId.merge(Usuarios2, how='left', left_on='Identidad', right_on='Identidad')\n",
    "    filtroId= filtroId.drop_duplicates(filtroId.columns[~filtroId.columns.isin(['Cruce'])], keep='first')\n",
    "    total = pd.concat([total, filtroId])\n",
    "    \n",
    "    total.index = range(total.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignarSistema (servidor):\n",
    "    servidores = {'amxprdecc': 'SAP 6.0', 'AMXPRDECC':'SAP 6.0','lnxremedy':'MyIT', 'colbtasga':'SGA', 'com103':'MAGUARE', 'comhp01':'SICACOM',\n",
    "    'comhp06':'SICACOM','comhp15':'SICACOM',\n",
    "    'comhp3':'AC - BSCS - MOTOR DE PAGOS', 'comhp43':'MOTOR DE PAGOS', 'comibm10':'MAHINDRA', 'comibm17':'CALLIDUS', 'comibm18':'CALLIDUS',\n",
    "    'lnxpretup':'MAHINDRA', 'lnxracdbpr':'CA', 'comsun10':'MAGUARE', 'lnxrmmitprd':'MyIT','comsun7':'INTEGRADOR WEB', 'comsun':'CALLIDUS',\n",
    "    'el01cn':'OIM', 'GSRCMDBTRI3':'MAXIMO', 'lnxdbussd':'MAHINDRA', 'lnxdb':'SGA', 'lnxgwussd':'MAHINDRA', 'lnxm':'INTEC','LNXM':'INTEC',\n",
    "    'lnxo':'INTEGRADOR WEB', 'lnxrrsso':'MyIT', 'lnxsoa12':'INTEGRADOR WEB', 'LNXFTP02':'INTEGRADOR WEB', 'wpol':'POLIEDRO', 'wcdbrmm':'MyIT',\n",
    "    'wcosql':'CRM-ONIX', 'colbtafile':'SGA'}\n",
    "    for c in servidores:\n",
    "        s = servidor.find(c)\n",
    "        if s != -1:\n",
    "            return servidores[c]\n",
    "\n",
    "if not total.empty : \n",
    "    total['Nombre_SO']=total['Nombre_SO'].astype(str)\n",
    "    total['Nombre_Sistema'] = total.apply(lambda x: asignarSistema(x['Nombre_SO']), axis=1)\n",
    "    total= total[['Nombre_SO', 'Nombre_Sistema', 'Identidad', 'Nombre', 'Estado', 'Documento', 'Cruce', 'DocumentoRRHH', 'NombreRRHH', 'CASO', 'FECHA DE RETIRO', 'TIPO DE CONTRATO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exists_SSFF_Activos = os.path.exists(filenameS+\"\\\\Informe_Activos_Claro.xlsx\")#Pregunta si en la ruta existe el archivo\n",
    "\n",
    "print(file_exists_SSFF_Activos)#muestra false o true \n",
    "\n",
    "if file_exists_SSFF_Activos == True:#Si el archivo existe\n",
    "\n",
    "    SsffA=pd.read_excel(filenameS+\"\\\\Informe_Activos_Claro.xlsx\")\n",
    "    SsffA.columns = SsffA.columns.str.strip()\n",
    "    SsffA=SsffA[['Cédula','Detalles de empleo Fecha de ingreso','Estado de colaborador']] #Usar solo las columnas que necesitamos\n",
    "    SsffA.rename(columns={'Estado de colaborador':'STATUS SSFF', 'Cédula':'DocumentoRRHH', 'Detalles de empleo Fecha de ingreso':'Fecha Ingreso SSFF'}, inplace=True)\n",
    "    SsffA.insert(loc = 3,column = 'Fecha Terminacion SSFF',value = '0')\n",
    "    SsffA=SsffA[['STATUS SSFF',  'DocumentoRRHH', 'Fecha Ingreso SSFF', 'Fecha Terminacion SSFF']]\n",
    "\n",
    "    SsffA = SsffA.sort_values('Fecha Ingreso SSFF', ascending=False)\n",
    "    SsffA['Fecha Ingreso SSFF'] = pd.to_datetime(SsffA['Fecha Ingreso SSFF'], format=\"%d/%m/%Y %H:%M:%S\" , errors='coerce')\n",
    "    SsffA['Fecha Ingreso SSFF'] = SsffA['Fecha Ingreso SSFF'].dt.floor('D')\n",
    "    pd.options.display.float_format = '{:.0f}'.format\n",
    "    SsffA['DocumentoRRHH']= SsffA['DocumentoRRHH'].astype('Int64')\n",
    "\n",
    "    SsffA['DocumentoRRHH'] = SsffA['DocumentoRRHH'].astype(str)\n",
    "\n",
    "    SsffA = SsffA.dropna(subset=[\"DocumentoRRHH\"])\n",
    "    \n",
    "    SsffA['DocumentoRRHH'] = [ele.lstrip('0') for ele in SsffA['DocumentoRRHH']]\n",
    "    SsffA['DocumentoRRHH'] = [ele.lstrip(' ') for ele in SsffA['DocumentoRRHH']]\n",
    "    SsffA['DocumentoRRHH'] = [ele.rstrip(' ') for ele in SsffA['DocumentoRRHH']]\n",
    "\n",
    "    SsffA=SsffA.drop_duplicates(SsffA.columns[~SsffA.columns.isin(['Fecha Ingreso SSFF'])], keep='first')\n",
    "    SsffA=SsffA[['STATUS SSFF',  'DocumentoRRHH', 'Fecha Ingreso SSFF', 'Fecha Terminacion SSFF']]\n",
    "\n",
    "    total = total.merge(SsffA, how='left', left_on='DocumentoRRHH', right_on='DocumentoRRHH')\n",
    "    total = total.fillna({'STATUS SSFF': 'Inactivo','FECHA DE RETIRO': 'N/A', 'Fecha Ingreso SSFF':'0', 'Fecha Terminacion SSFF':'0'}) \n",
    "    \n",
    "    # total['Fecha Terminacion SSFF'] = pd.to_datetime(Nube['Fecha Terminacion SSFF'], format=\"%d/%m/%Y\" , errors='ignore')\n",
    "    # Nube['FECHA DE RETIRO'] = pd.to_datetime(Nube['FECHA DE RETIRO'], format=\"%Y/%m/%d\" , errors='coerce')\n",
    "    total=total.drop_duplicates(total.columns[~total.columns.isin(['STATUS SSFF', 'Fecha Ingreso SSFF', 'Fecha Terminacion SSFF'])], keep='first')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=total.assign(Reintegro='N/A')\n",
    "total['Nombre']=total['Nombre'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not total.empty== True:\n",
    "    total.insert(loc=13, column='Aplica inactivacion', value  = 'si')\n",
    "    # total.loc[(total['coincidencia nombre APP vs SSFF'] >= 25) , 'Aplica inactivacion']='si'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not total.empty== True: \n",
    "    total= total[['Nombre_SO','Nombre_Sistema', 'Identidad', 'Nombre', 'Estado', 'Documento', 'Cruce',  'DocumentoRRHH','NombreRRHH', 'CASO',\n",
    "                'FECHA DE RETIRO', 'TIPO DE CONTRATO', 'STATUS SSFF', 'Fecha Ingreso SSFF',\n",
    "                'Fecha Terminacion SSFF', 'Reintegro', 'Aplica inactivacion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_actual = str(datetime.now().date())\n",
    "hora_actual = datetime.now().time()\n",
    "hora_actual = hora_actual.strftime('%H-%M-%S')\n",
    "\n",
    "nombref=filename+'\\\\IdentidadesSOconSSFF '+fecha_actual+' '+hora_actual+'.csv'\n",
    "total.to_csv(nombref,index=False,sep=';',encoding='utf-8-sig')\n",
    "nombre1=filename+'\\\\IdentidadesSOconSSFF.csv'\n",
    "total.to_csv(nombre1,index=False,sep=';',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bab93407023da92fecc0d42af32359b73fde05971fc756dcf35991659248e545"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
